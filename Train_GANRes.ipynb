{
 "cells": [
  {
   "cell_type": "code",
   "id": "6831ed8a-e47c-4731-b01f-61b68e7afeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:00:08.412308Z",
     "start_time": "2025-06-23T03:00:06.474896Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from Models.LargePNet import *\n",
    "import tifffile\n",
    "from Models.Discriminator import *\n",
    "from Utils.TrainerRaGAN32 import *\n",
    "from Utils.AppendLoad import *"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\.conda\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a9678749-131e-4b7e-8c0d-0a0e36851780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:05:28.525111Z",
     "start_time": "2025-06-23T03:05:27.405551Z"
    }
   },
   "source": [
    "# Load Raw .npz data\n",
    "Data_dir = r'F:\\Datasets\\STED_deblurring\\MitoInner\\Training'\n",
    "loaded_data = np.load(Data_dir + '\\MitoDeblurdata.npz')\n",
    "X_train = loaded_data['X_train']  \n",
    "y_train = loaded_data['y_train']\n",
    "X_val = loaded_data['X_val']\n",
    "y_val = loaded_data['y_val']\n",
    "log_dir = Data_dir + r'\\logfile'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "# Create training and validation data\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32).unsqueeze(1)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32).unsqueeze(1)\n",
    "X_val = torch.tensor(X_val, dtype = torch.float32).unsqueeze(1)\n",
    "y_val = torch.tensor(y_val, dtype = torch.float32).unsqueeze(1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "''' Another loading method: load .tif image file\n",
    "head_dir = r\"E:\\SMLM\\MT\\512data\\Training\"\n",
    "Training_GT_path = head_dir + '\\\\' + r'GT\\*.tif'\n",
    "Training_Raw_path = head_dir + '\\\\' + r'Noisy\\*.tif'\n",
    "Val_GT_path = head_dir + '\\\\' + r'ValGT\\*.tif'\n",
    "Val_Raw_path = head_dir + '\\\\' + r'ValNoisy\\*.tif'\n",
    "\n",
    "X_train = AppendLoad(Training_Raw_path)\n",
    "y_train = AppendLoad(Training_GT_path)\n",
    "X_val = AppendLoad(Val_Raw_path)\n",
    "y_val = AppendLoad(Val_GT_path)\n",
    "\n",
    "print(\"X_train.shape\",X_train.shape)\n",
    "print(\"y_train.shape\",y_train.shape)\n",
    "print(\"X_val.shape\",X_val.shape)\n",
    "print(\"y_val.shape\",y_val.shape)\n",
    "\n",
    "train_data = Data.TensorDataset(X_train,y_train)\n",
    "val_data = Data.TensorDataset(X_val,y_val)\n",
    "'''"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288, 1, 1024, 1024])\n",
      "torch.Size([288, 1, 1024, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Another loading method: load .tif image file\\nhead_dir = r\"E:\\\\SMLM\\\\MTŊdata\\\\Training\"\\nTraining_GT_path = head_dir + \\'\\\\\\' + r\\'GT\\\\*.tif\\'\\nTraining_Raw_path = head_dir + \\'\\\\\\' + r\\'Noisy\\\\*.tif\\'\\nVal_GT_path = head_dir + \\'\\\\\\' + r\\'ValGT\\\\*.tif\\'\\nVal_Raw_path = head_dir + \\'\\\\\\' + r\\'ValNoisy\\\\*.tif\\'\\n\\nX_train = AppendLoad(Training_Raw_path)\\ny_train = AppendLoad(Training_GT_path)\\nX_val = AppendLoad(Val_Raw_path)\\ny_val = AppendLoad(Val_GT_path)\\n\\nprint(\"X_train.shape\",X_train.shape)\\nprint(\"y_train.shape\",y_train.shape)\\nprint(\"X_val.shape\",X_val.shape)\\nprint(\"y_val.shape\",y_val.shape)\\n\\ntrain_data = Data.TensorDataset(X_train,y_train)\\nval_data = Data.TensorDataset(X_val,y_val)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:05:55.793296Z",
     "start_time": "2025-06-23T03:05:38.370512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Augment data\n",
    "img_num = X_train.shape[0]\n",
    "img_num_val = X_val.shape[0]\n",
    "wanted_num = 2000\n",
    "aimingsize = 512\n",
    "background_control_max = 0.05\n",
    "background_control_mean = 0.02 # typically 0.015-0.03\n",
    "\n",
    "X_train_expand = []\n",
    "y_train_expand = []\n",
    "X_val_expand = []\n",
    "y_val_expand = []\n",
    "crop_num = wanted_num // img_num\n",
    "\n",
    "count = 0\n",
    "for i in tqdm(range(img_num), desc=\"Processing images\"):  \n",
    "    raw = X_train[i,0,...]\n",
    "    gt = y_train[i,0,...]\n",
    "    raw = np.expand_dims(raw,axis=2)\n",
    "    gt = np.expand_dims(gt,axis=2)\n",
    "    for j in range (crop_num):\n",
    "        Augraw, Auggt = DataAug(raw,gt,aimingsize)\n",
    "        if Auggt.max()>background_control_max:\n",
    "            if Auggt.mean()>background_control_mean:\n",
    "                X_train_expand.append(Augraw.squeeze())\n",
    "                y_train_expand.append(Auggt.squeeze())\n",
    "                count = count + 1\n",
    "X_train = np.array(X_train_expand)\n",
    "y_train = np.array(y_train_expand)\n",
    "\n",
    "count = 0\n",
    "for i in tqdm(range(img_num_val), desc=\"Processing images\"):  \n",
    "    raw = X_val[i,0,...]\n",
    "    gt = y_val[i,0,...]\n",
    "    raw = np.expand_dims(raw,axis=2)\n",
    "    gt = np.expand_dims(gt,axis=2)\n",
    "    for j in range (crop_num//2):\n",
    "        Augraw, Auggt = DataAug(raw,gt,aimingsize)\n",
    "        if Auggt.max()>background_control_max:\n",
    "            if Auggt.mean()>background_control_mean:\n",
    "                X_val_expand.append(Augraw.squeeze())\n",
    "                y_val_expand.append(Auggt.squeeze())\n",
    "                count = count + 1\n",
    "X_val = np.array(X_val_expand)\n",
    "y_val = np.array(y_val_expand)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32).unsqueeze(1)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32).unsqueeze(1)\n",
    "X_val = torch.tensor(X_val, dtype = torch.float32).unsqueeze(1)\n",
    "y_val = torch.tensor(y_val, dtype = torch.float32).unsqueeze(1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "train_data = Data.TensorDataset(X_train,y_train)\n",
    "val_data = Data.TensorDataset(X_val,y_val)"
   ],
   "id": "a86a7407c1146639",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 288/288 [00:11<00:00, 24.14it/s]\n",
      "Processing images: 100%|██████████| 48/48 [00:01<00:00, 42.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1580, 1, 512, 512])\n",
      "torch.Size([1580, 1, 512, 512])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "03cdb273-2788-40c9-828d-2cae506606d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:07:53.315683Z",
     "start_time": "2025-06-23T03:07:53.301675Z"
    }
   },
   "source": [
    "class Options:  \n",
    "    def __init__(self):  \n",
    "        self.LR = 0.001\n",
    "        self.batchsize = 1 \n",
    "        self.epoch_num = 50 \n",
    "        self.MSE_weight = 0\n",
    "        self.MAE_weight = 1   \n",
    "        self.SSIM_weight = 0 \n",
    "        self.epoch_critic = 10\n",
    "        self.useinit = 0\n",
    "        self.ModelType = 1   \n",
    "        self.loss_content = 0.006\n",
    "        self.loss_GAN = 0.001\n",
    "        self.D_decay = 500   # Decay of dicriminator leraning rate over generator\n",
    "        self.warmupepoch = 0\n",
    "        self.Dinterval = 1\n",
    "        self.StepLR = 1\n",
    "        self.ExpoLR = 0\n",
    "        self.val = 1\n",
    "        self.test = 0\n",
    "        self.use_dir = 0\n",
    "        self.use_norm = 1\n",
    "        self.val_data_dir = ''\n",
    "        self.innerpoint = []\n",
    "        self.instanceimage = ''\n",
    "        self.val_start = 10\n",
    "opt = Options()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "15f03728-f2f9-4446-9f6c-c741eb7d45ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T04:54:37.368741Z",
     "start_time": "2025-06-23T03:07:53.848715Z"
    }
   },
   "source": [
    "netG = LargePNet(1,1,1,25,4)\n",
    "hr_shape = (512,512)\n",
    "netD = MultiScaleDiscriminator(input_shape = (1, *hr_shape))\n",
    "save_path = Data_dir+r'\\logfile\\LargePGAN'\n",
    "TrainerRaGAN32(netG, netD, train_data, val_data, save_path, opt)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop path: Identity()\n",
      "drop path: Identity()\n",
      "drop path: Identity()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\.conda\\envs\\DL\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "C:\\Users\\Dell\\.conda\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\.conda\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [09:17<00:00,  2.83it/s, Epoch: 1, Loss: 0.020300325006246567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss_D: 0.3889, Loss_G: 0.0438, D(x): 0.3889, D(z): 0.3889\n",
      "Epoch: 0, Val Loss: 0.001099, Val MSE: 0.001099, Val MAE: 0.018017, Val SSIM: 0.923970\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [09:45<00:00,  2.70it/s, Epoch: 2, Loss: 0.029411477968096733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss_D: 0.3500, Loss_G: 0.0219, D(x): 0.3500, D(z): 0.3500\n",
      "Epoch: 1, Val Loss: 0.001071, Val MSE: 0.001071, Val MAE: 0.017589, Val SSIM: 0.928700\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [09:39<00:00,  2.73it/s, Epoch: 3, Loss: 0.011040061712265015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss_D: 0.3301, Loss_G: 0.0214, D(x): 0.3301, D(z): 0.3301\n",
      "Epoch: 2, Val Loss: 0.000978, Val MSE: 0.000978, Val MAE: 0.016832, Val SSIM: 0.933691\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [09:32<00:00,  2.76it/s, Epoch: 4, Loss: 0.025355413556098938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss_D: 0.3464, Loss_G: 0.0210, D(x): 0.3464, D(z): 0.3464\n",
      "Epoch: 3, Val Loss: 0.001151, Val MSE: 0.001151, Val MAE: 0.018021, Val SSIM: 0.924868\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [10:09<00:00,  2.59it/s, Epoch: 5, Loss: 0.02618771605193615] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss_D: 0.3654, Loss_G: 0.0209, D(x): 0.3654, D(z): 0.3654\n",
      "Epoch: 4, Val Loss: 0.001697, Val MSE: 0.001697, Val MAE: 0.021280, Val SSIM: 0.914445\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [08:58<00:00,  2.93it/s, Epoch: 6, Loss: 0.02076788991689682] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss_D: 0.3717, Loss_G: 0.0206, D(x): 0.3717, D(z): 0.3717\n",
      "Epoch: 5, Val Loss: 0.000940, Val MSE: 0.000940, Val MAE: 0.016714, Val SSIM: 0.933892\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [08:53<00:00,  2.96it/s, Epoch: 7, Loss: 0.019438298419117928] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss_D: 0.3842, Loss_G: 0.0204, D(x): 0.3842, D(z): 0.3842\n",
      "Epoch: 6, Val Loss: 0.000893, Val MSE: 0.000893, Val MAE: 0.016277, Val SSIM: 0.937126\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [08:52<00:00,  2.97it/s, Epoch: 8, Loss: 0.012843376025557518] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss_D: 0.3846, Loss_G: 0.0202, D(x): 0.3846, D(z): 0.3846\n",
      "Epoch: 7, Val Loss: 0.000860, Val MSE: 0.000860, Val MAE: 0.016306, Val SSIM: 0.932409\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [08:53<00:00,  2.96it/s, Epoch: 9, Loss: 0.015912024304270744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss_D: 0.3984, Loss_G: 0.0201, D(x): 0.3984, D(z): 0.3984\n",
      "Epoch: 8, Val Loss: 0.001014, Val MSE: 0.001014, Val MAE: 0.016909, Val SSIM: 0.936306\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [08:52<00:00,  2.97it/s, Epoch: 10, Loss: 0.012492291629314423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss_D: 0.4074, Loss_G: 0.0200, D(x): 0.4074, D(z): 0.4074\n",
      "Epoch: 9, Val Loss: 0.001230, Val MSE: 0.001230, Val MAE: 0.018632, Val SSIM: 0.927455\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1580/1580 [08:52<00:00,  2.97it/s, Epoch: 11, Loss: 0.033062901347875595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss_D: 0.4196, Loss_G: 0.0197, D(x): 0.4196, D(z): 0.4196\n",
      "Epoch: 10, Val Loss: 0.000934, Val MSE: 0.000934, Val MAE: 0.017245, Val SSIM: 0.926208\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  12%|█▏        | 195/1580 [01:10<08:17,  2.78it/s, Epoch: 12, Loss: 0.02089753746986389] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m netD \u001B[38;5;241m=\u001B[39m MultiScaleDiscriminator(input_shape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m*\u001B[39mhr_shape))\n\u001B[0;32m      4\u001B[0m save_path \u001B[38;5;241m=\u001B[39m Data_dir\u001B[38;5;241m+\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mlogfile\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mLargePGAN\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mTrainerRaGAN32\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnetD\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\SourceCode\\Utils\\TrainerRaGAN32.py:249\u001B[0m, in \u001B[0;36mTrainerRaGAN32\u001B[1;34m(netG, netD, train_data, val_data, save_path, opt)\u001B[0m\n\u001B[0;32m    246\u001B[0m loss_content \u001B[38;5;241m=\u001B[39m criterion_content(fake_img, b_y)\n\u001B[0;32m    247\u001B[0m loss_G \u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39mloss_GAN \u001B[38;5;241m*\u001B[39m loss_GAN \u001B[38;5;241m+\u001B[39m pixel_loss \u001B[38;5;241m+\u001B[39m opt\u001B[38;5;241m.\u001B[39mloss_content \u001B[38;5;241m*\u001B[39m loss_content\n\u001B[1;32m--> 249\u001B[0m \u001B[43mloss_G\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    250\u001B[0m optimizerG\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    252\u001B[0m \u001B[38;5;66;03m# (2) Update D network: maximize D(x)-1-D(G(z))\u001B[39;00m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;66;03m# with autocast():\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DL\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DL\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
